import os
import sys
sys.path.append(r"D:\PhD\YieldProject\Scripts\03_Modelling")
import warnings
from copy import deepcopy
import yieldfunctions as yf
import pandas as pd
import geopandas as gpd
import numpy as np
from random import sample
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
import tensorflow_probability as tfp
from tensorflow.keras.callbacks import EarlyStopping

tfd = tfp.distributions
warnings.filterwarnings("ignore")
pd.set_option('display.max_columns', None)
import importlib
importlib.reload(yf)

dataDir = r"D:\PhD\YieldProject\Data\Final"
trainDir = r"D:\PhD\YieldProject\Output_Detrended\Training"
synthDir_monthly = r"D:\PhD\YieldProject\Output_Detrended\Synthetic"
#synthDir_weekly = r"D:\PhD\YieldProject\Output_Detrended\Synthetic_WeeklyByTWP"
predDir = r"D:\PhD\YieldProject\Output_Detrended\Predictions"
modelDir = r"D:\PhD\YieldProject\Output_Detrended\Models"

os.makedirs(synthDir_monthly, exist_ok=True)
#os.makedirs(synthDir_weekly, exist_ok=True)

# First, get valid TWP_IDs after filtering
df_pred = pd.read_csv(predDir + "//AllPredictions_AllWeeks.csv")
twps = np.unique(df_pred.TWP_ID)

# Get orig df
# df = pd.read_csv(dataDir + f"//wheat_AllYears.csv")
# df = df[df['TWP_ID'].isin(twps)]

# Filter out rows >17 if they aren't in df_pred
# filter_week_less_18 = df[df['Week'] < 18]
# filter_week_greater_equal_18 = pd.merge(df[df['Week'] >= 18], df_pred, how='inner', on=['TWP_ID', 'Year', 'Week'])
# df = pd.concat([filter_week_less_18, filter_week_greater_equal_18], ignore_index=True)

w = [18,19,20,21]
#w = list(range(18, 39))
#w.reverse()
# This data frame is the synthetic data for one week
df_agg = df_pred.groupby('TWP_ID').agg(
    Long=('Long', 'first'),
    Lat=('Lat', 'first'),
    MeanTotalYield=('TotalYield', 'mean'),
    StdTotalYield=('TotalYield', 'std')
).reset_index()
# Get rows for use later
n_twp = len(df_agg)
cats = [0,1,2,3,4,5]
ndvi_levels = ["-1SD", "Mean", "+1SD"]
changeweeks = [18, 22, 27, 31, 36]
month_dict = {'April': list(range(15, 18)), 'May': list(range(18, 22)), 'June': list(range(22, 27)),
              'July': list(range(27, 31)), 'August': list(range(31, 36)), 'September': list(range(36, 39))}
# Predictors (ModeCDM, WMeanNDVI) for previous weeks need to be added before running the model for each week
for week in w:
    print(week)
    str_week = str(week)
    if not os.path.exists(synthDir_monthly + f"//SyntheticPreds_wheat_Week{str_week}.csv"):
        # Get training data
        training = pd.read_csv(trainDir + f"//Training_wheat_Week{str_week}.csv")
        training = training[training['TWP_ID'].isin(twps)]
        training = training.sort_values(by='TWP_ID').reset_index(drop=True)
        # Multiply this df by 6 so we can test for each CDM cat (ND, D0..,D4), then by 3 for each ndvi level (-1SD, etc)
        df_synth = pd.concat([df_agg] * (len(cats)) * len(ndvi_levels), ignore_index=True)
        df_week = deepcopy(df_synth)
        df_week['Ndvi_Levels'] = [x for x in ndvi_levels for _ in range(n_twp*6)] # Add ndvi_lvels
        # Add ModeCDM values
        predweeks = list(range(15, week+1)) if week < 19 else list(range(week-4, week+1)) # All weeks included
        for predweek in predweeks:
            predweek_str = str(predweek)
            if week in [15,16,17]:
                df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)] * 3
            elif week in changeweeks:
                if predweek == max(predweeks): # First WOTM, CDM that week should be one higher (except ND)
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)] * 3
                else: # Previous months are -1 except ND
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in [0] + cats[:-1] for _ in range(n_twp)] * 3
            elif week in [x+1 for x in changeweeks]: # If week is the second of the month
                if predweek in [max(predweeks), max(predweeks)-1]: # Weeks in the current month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)] * 3
                else: # Weeks in prior month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in [0] + cats[:-1] for _ in range(n_twp)] * 3
            elif week in [x+2 for x in changeweeks]: # If week is the third of the month
                if predweek in [max(predweeks), max(predweeks)-1, max(predweeks)-2]: # Weeks in the current month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)] * 3
                else: # Weeks in prior month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in [0] + cats[:-1] for _ in range(n_twp)] * 3
            elif week in [x+3 for x in changeweeks]: # If week is the fourth of the month
                if predweek in [max(predweeks), max(predweeks)-1, max(predweeks)-2, max(predweeks)-3]: # Weeks in the current month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)] * 3
                else: # Weeks in prior month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in [0] + cats[:-1] for _ in range(n_twp)] * 3
            elif week in [x+4 for x in changeweeks]: # If week is the fifth of the month (26, 35)
                if predweek in [max(predweeks), max(predweeks)-1, max(predweeks)-2, max(predweeks)-3, max(predweeks)-4]: # Weeks in the current month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)] * 3
                else: # Weeks in prior month
                    df_week[f'ModeCDM_{predweek_str}'] = [x for x in [0] + cats[:-1] for _ in range(n_twp)] * 3
        df_week_monthlycdm = deepcopy(df_week)
        df_week_weeklytwp = deepcopy(df_week)
        for predweek in predweeks:
            predweek_str = str(predweek)
            ################################# MonthlyBYCDM #############################################
            month = next((k for k, v in month_dict.items() if predweek in v), None)
            monthweeks = month_dict[month]
            for cdm in cats:
                mndvi_cdm = df_pred[(df_pred['ModeCDM'] == cdm) & (df_pred['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].mean()
                sndvi_cdm = df_pred[(df_pred['ModeCDM'] == cdm) & (df_pred['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].std()
                plusndvi_cdm = mndvi_cdm + sndvi_cdm
                minusndvi_cdm = mndvi_cdm - sndvi_cdm
                if (cdm in [4,5]):
                    # Correct for strange ndvi figures due to low sample size of D4 by taking D3-(D2-D3) NDVI numbers as a linear interp
                    mndvi_cdm_prev = df_pred[(df_pred['ModeCDM'] == cdm-1) & (df_pred['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].mean()
                    if mndvi_cdm > mndvi_cdm_prev:
                        mndvi_cdm_prev2 = df_pred[(df_pred['ModeCDM'] == cdm - 2) & (df_pred['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].mean()
                        mndvi_cdm = mndvi_cdm_prev - (mndvi_cdm_prev2 - mndvi_cdm_prev)
                df_week_monthlycdm.loc[(df_week_monthlycdm['Ndvi_Levels'] == "Mean") & (df_week_monthlycdm[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
                    mndvi_cdm
                )
                df_week_monthlycdm.loc[(df_week_monthlycdm['Ndvi_Levels'] == "+1SD") & (df_week_monthlycdm[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
                    plusndvi_cdm
                )
                df_week_monthlycdm.loc[(df_week_monthlycdm['Ndvi_Levels'] == "-1SD") & (df_week_monthlycdm[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
                    minusndvi_cdm
                )
            ################################# WEEKLYBYTWP #############################################
            # df_subweeks = df[df['Week'].isin([predweek, predweek-1, predweek-2])]
            # df_twp = pd.DataFrame(data={'TWP_ID': [x for x in df_week_weeklytwp.TWP_ID.unique()] * 3,
            #                             'Ndvi_Levels': [x for x in ['Mean', '-1SD', '+1SD'] for _ in
            #                                             range(len(df_week_weeklytwp.TWP_ID.unique()))]})
            # df_twp = df_twp.sort_values(by='TWP_ID').reset_index(drop=True)
            # # NDVI Level Mean by TWP, join to df_week - WeeklybyTWP with a 3-week running mean NDVI
            # df_twp.loc[df_twp['Ndvi_Levels'] == "Mean", f'WMeanNdvi_{predweek_str}'] = df_subweeks.groupby('TWP_ID').apply(
            #     lambda x: x[f'WMeanNdvi'].mean()).values
            # df_twp.loc[df_twp['Ndvi_Levels'] == "-1SD", f'WMeanNdvi_{predweek_str}'] = df_subweeks.groupby('TWP_ID').apply(
            #     lambda x: x[f'WMeanNdvi'].mean() - x[f'WMeanNdvi'].std()).values
            # df_twp.loc[df_twp['Ndvi_Levels'] == "+1SD", f'WMeanNdvi_{predweek_str}'] = df_subweeks.groupby('TWP_ID').apply(
            #     lambda x: x[f'WMeanNdvi'].mean() + x[f'WMeanNdvi'].std()).values
            # df_week_weeklytwp = df_week_weeklytwp.merge(df_twp, on=['TWP_ID', 'Ndvi_Levels'], how='left')

        # Create model on full dataset
        training = training.drop(columns=['MeanTotalYield', 'StdTotalYield'])
        training['MeanTotalYield'] = training.groupby('TWP_ID')['TotalYield'].transform('mean')
        training['StdTotalYield'] = training.groupby('TWP_ID')['TotalYield'].transform('std')
        X = training.loc[:, training.columns != "TotalYield"]
        y = training.loc[:, training.columns == "TotalYield"].squeeze()
        X_noID = X.drop(columns=['TWP_ID', 'Year'])
        keras.backend.clear_session()
        # dataset_size = len(X_noID)
        # kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(dataset_size, dtype=tf.float32))
        # model_tfp = tf.keras.Sequential([
        #     keras.layers.BatchNormalization(),
        #     tfp.layers.DenseFlipout(96, kernel_divergence_fn=kl_divergence_function),
        #     keras.layers.ReLU(),
        #     tfp.layers.DenseFlipout(448, kernel_divergence_fn=kl_divergence_function),
        #     keras.layers.ReLU(),
        #     tfp.layers.DenseFlipout(160, kernel_divergence_fn=kl_divergence_function),
        #     keras.layers.ReLU(),
        #     keras.layers.Dense(2)
        # ])
        # loss_fun = yf.testloss_3 if week in list(range(16, 19)) + list(range(28, 36)) else yf.testloss
        # model_tfp.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=loss_fun)
        # # Add ES
        # early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        # model_tfp.fit(X_noID.values,
        #               y.values,
        #               epochs=500,
        #               batch_size=32,
        #               verbose=0,
        #               use_multiprocessing=True,
        #               callbacks=[early_stopping],
        #               validation_split=0.25,
        #               )
        # model_tfp.save(modelDir + f"//WheatModel_Week{str_week}")
        model_tfp = tf.keras.models.load_model(modelDir + f"//WheatModel_Week{str_week}", compile=False)
        print ("Model Loaded")
        # Predict
        for aggmethod in ['Monthly']: #, 'Weekly']:
            if aggmethod == 'Monthly':
                df_aggmethod = deepcopy(df_week_monthlycdm)
                synthDir = synthDir_monthly
            else:
                df_aggmethod = deepcopy(df_week_weeklytwp)
                synthDir = synthDir_weekly
            # First, prep synthetic data
            df_test = df_aggmethod.drop(columns=['TWP_ID', 'Ndvi_Levels'])
            df_test = df_test.reindex(columns=X_noID.columns)
            num_monte_carlo_samples = 100
            # Predict
            predictions = [model_tfp.predict(df_test.values, batch_size=1024, verbose=0) for _ in
                           range(num_monte_carlo_samples)]
            predictions = np.array(predictions).squeeze()
            mean_preds = np.mean(predictions[:, :, 0], axis=0)
            mean_stdev = np.mean(np.exp(predictions[:, :, 1]), axis=0)
            stdev_means = np.std(predictions[:, :, 0], axis=0)
            stdev_preds = mean_stdev + stdev_means

            # Add to df
            df_aggmethod["MeanYieldPred"] = mean_preds
            df_aggmethod["StdYieldPred"] = stdev_preds
            df_aggmethod["Week"] = week
            df_aggmethod.to_csv(synthDir + f"//SyntheticPreds_wheat_Week{str_week}.csv", index = False)
