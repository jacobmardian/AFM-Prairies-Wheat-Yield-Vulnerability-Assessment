# -*- coding: utf-8 -*-
"""
Created on Tue May 23 13:14:53 2023

@author: jacob
"""
import os
import sys
import warnings
from copy import deepcopy
from random import sample
sys.path.append(r"D:\PhD\YieldProject\Scripts\03_Modelling")
import yieldfunctions as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
import tensorflow_probability as tfp
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.feature_selection import r_regression
import importlib
importlib.reload(yf)

# init
tfd = tfp.distributions
warnings.filterwarnings("ignore")

# User Parameters
crop = "wheat" # wheat or canola
dataDir = r"D:\PhD\YieldProject\Data\Final"
modelDir = r"D:\PhD\YieldProject\Output_Detrended\Models"
accDir = r"D:\PhD\YieldProject\Output_Detrended\Accuracy"
predDir = r"D:\PhD\YieldProject\Output_Detrended\Predictions"
plotDir = r"D:\PhD\YieldProject\Output_Detrended\Plots"
trainDir = r"D:\PhD\YieldProject\Output_Detrended\Training"
os.makedirs(modelDir, exist_ok=True)
os.makedirs(accDir, exist_ok=True)
os.makedirs(predDir, exist_ok=True)
os.makedirs(plotDir, exist_ok=True)
os.makedirs(trainDir, exist_ok=True)

keepPreds = ['Lat', 'Long', 'MeanTotalYield', 'StdTotalYield', 'ModeCDM', 'WMeanNdvi']#,'WStdevNdvi'] #'CVNdvi', 'IQRNdvi', 'RangeNdvi']
response = 'DTYield'
numWeeks = 4 # Number of weeks to include as predictors

# Load dataset
df = pd.read_csv(dataDir + f"//{crop}_AllYears.csv")

if response == 'YieldAnomStd':
    df = df.drop(columns = ['YieldAnom', "TotalYield"])
elif response == 'YieldAnom':
    df = df.drop(columns = ['YieldAnomStd', "TotalYield"])
elif response == "TotalYield":
    df = df.drop(columns = ['YieldAnomStd', 'YieldAnom'])
elif response == "DTYield":
    df = df.drop(columns = ['MeanTotalYield', 'StdTotalYield', 'YieldAnomStd', 'YieldAnom', ])
    # Can only dt full ts so remove TWP_IDs that don't have data each year
    from scipy import stats
    def detrend(group):
        slope, intercept, r_value, p_value, std_err = stats.linregress(group['Year'], group['TotalYield'])
        trend = slope * group['Year'] + intercept
        group['DTYield'] = group['TotalYield'] - trend + group['TotalYield'].mean()
        group['MeanTotalYield'] = group['DTYield'].mean()
        group['StdTotalYield'] = group['DTYield'].std()
        return group
    detrended = df.groupby('TWP_ID').apply(detrend).reset_index(drop=True)
    df = pd.merge(df, detrended[['TWP_ID', 'Year', 'Week', 'DTYield', 'MeanTotalYield', 'StdTotalYield']],
                  on=['TWP_ID', 'Year', 'Week'], how='left')
    df = df.drop(columns = ['TotalYield'])
    df = df.rename(columns = {'DTYield': 'TotalYield'})
    response = 'TotalYield'

drop = list(set(list(df.columns)) - set(keepPreds + ['TWP_ID'] + ['Year'] + ['Week'] + [response]))
df = df.drop(columns = drop)
df_preds = deepcopy(df)

# Define variables from data
years = np.unique(df.Year)
#weeks = np.unique(df.Week)
# weeks = list(range(15, 39))
weeks = [18]

# year = 2015
# week = 35

# Init
d = {'Week': list(range(15,39)), 'MSE': np.nan, 'MAE': np.nan, 'R2': np.nan, 'r': np.nan, 'ic68': np.nan, 'ic95': np.nan, 'ic99': np.nan}
df_acc = pd.DataFrame(data = d)

# Time series CV set up and run model
for week in weeks:
    print (week)
    str_week = str(week)
    df_week = df[(df.Week <= week)]
    df_week.reset_index(inplace=True, drop=True)
    # We need a single row for each TWP_ID with predictors as columns
    keepCols = keepPreds + [response] + ['Long'] + ['Lat']
    df_week = df_week.pivot_table(index=['TWP_ID', 'Year'], columns='Week',
                                      values=keepCols, aggfunc='first')
    df_week.columns = df_week.columns.map(lambda x: f'{x[0]}_{x[1]}')
    df_week = df_week.loc[:, ~df_week.columns.str.match(f'^{response}_(?!15$)\d+$')]
    df_week = df_week.loc[:, ~df_week.columns.str.match(r'^MeanTotalYield_(?!15$)\d+$')]
    df_week = df_week.loc[:, ~df_week.columns.str.match(r'^StdTotalYield_(?!15$)\d+$')]
    df_week = df_week.loc[:, ~df_week.columns.str.match(r'^Long_(?!15$)\d+$')]
    df_week = df_week.loc[:, ~df_week.columns.str.match(r'^Lat_(?!15$)\d+$')]
    df_week = df_week.rename(columns={f'{response}_15': f'{response}'})
    df_week = df_week.rename(columns={'MeanTotalYield_15': 'MeanTotalYield'})
    df_week = df_week.rename(columns={'StdTotalYield_15': 'StdTotalYield'})
    df_week = df_week.rename(columns={'Long_15': 'Long'})
    df_week = df_week.rename(columns={'Lat_15': 'Lat'})
    cdmCols = df_week.filter(like='ModeCDM').columns.tolist()
    df_week[cdmCols] = df_week[cdmCols].astype('category')
    df_week = df_week.dropna()
    df_week.reset_index(inplace=True)
    if (week > 18):
        new_week = str(week-numWeeks)
        week_str0 = new_week[0]
        week_str1 = new_week[1]
        # REMOVE ALL DATA EXCEPT FOR THE LAST 5 WEEKS
        cols = []
        cols.extend(['TWP_ID', 'Long', 'Lat', 'Year', response, 'MeanTotalYield', 'StdTotalYield'])
        for pred in keepPreds:
            cols.extend(yf.filter_preds(df_week, pred, week_str0, week_str1))
        df_week = df_week.loc[:, cols]
        df_week = df_week.sort_values(by = ['Year', 'TWP_ID']).reset_index(drop = True)

    trainfile = trainDir + f"//Training_{crop}_Week{week}.csv"
    if not os.path.exists(trainfile):
        df_week.to_csv(trainfile, index = False)

        # initialize outcomes
        X = df_week.loc[:, df_week.columns != response]
        y = df_week.loc[:, df_week.columns == response].squeeze()
        # obs = np.empty(0)
        # bnn_mean = np.empty(0)
        # bnn_stdev = np.empty(0)
        # LOOCV
        for year in years:
            print (year)
            # Get indices for each year
            train_indices = X[X.Year != year].index
            test_indices = X[X.Year == year].index
            # Split into train/test
            X_train = X.iloc[train_indices]
            y_train = y[train_indices]
            X_test = X.iloc[test_indices]
            y_test = y[test_indices]
            # Reset index
            X_train.reset_index(inplace=True, drop=True)
            X_test.reset_index(inplace=True, drop=True)
            y_train.reset_index(inplace=True, drop=True)
            y_test.reset_index(inplace=True, drop=True)

            # Remove TWP_ID for modelling but keep it for plotting
            X_train_noID = X_train.drop(columns = ['TWP_ID', 'Year'])
            X_test_noID = X_test.drop(columns = ['TWP_ID', 'Year'])

            # BNN
            keras.backend.clear_session()
            dataset_size = len(X_train_noID)
            kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(dataset_size, dtype=tf.float32))
            model_tfp = tf.keras.Sequential([
                keras.layers.BatchNormalization(),
                tfp.layers.DenseFlipout(96, kernel_divergence_fn=kl_divergence_function),
                keras.layers.ReLU(),
                tfp.layers.DenseFlipout(448, kernel_divergence_fn=kl_divergence_function),
                keras.layers.ReLU(),
                tfp.layers.DenseFlipout(160, kernel_divergence_fn=kl_divergence_function),
                keras.layers.ReLU(),
                keras.layers.Dense(2)
            ])
            #loss_fun = yf.testloss_3 if week in list(range(15, 19)) + list(range(28, 36)) else yf.testloss
            loss_fun = yf.testloss_15
            model_tfp.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=loss_fun)#custom_loss)
            # Add ES
            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
            model_tfp.fit(X_train_noID.values,
                      y_train.values,
                      epochs=500,
                      batch_size = 32,
                      verbose=0,
                      use_multiprocessing=True,
                      callbacks=[early_stopping],
                      validation_split= 0.25,
                      )
            # Samples from posterior, getting mean and variance from each model run
            num_monte_carlo_samples = 100
            predictions = [model_tfp.predict(X_test_noID.values, batch_size=1024, verbose=0) for _ in
                           range(num_monte_carlo_samples)]
            predictions = np.array(predictions).squeeze()
            mean_preds = np.mean(predictions[:, :, 0], axis=0)
            mean_stdev = np.mean(np.exp(predictions[:, :, 1]), axis=0)
            stdev_means = np.std(predictions[:, :, 0], axis=0)
            stdev_preds = mean_stdev + stdev_means

            # Append obs and preds
            # obs = np.append(obs, y_test.values)
            # bnn_mean = np.append(bnn_mean, mean_preds)
            # bnn_stdev = np.append(bnn_stdev, stdev_preds)

            # Add preds to df_preds
            df_preds.loc[(df_preds['Week'] == week) & (df_preds['Year'] == year), f'PredMean_Week{week}'] = mean_preds
            df_preds.loc[(df_preds['Week'] == week) & (df_preds['Year'] == year), f'PredStd_Week{week}'] = stdev_preds

        # df_preds.loc[df_preds['Week'] == week, f'PredMean_Week{week}'] = bnn_mean
        # df_preds.loc[df_preds['Week'] == week, f'PredStd_Week{week}'] = bnn_stdev
        df_preds.to_csv(predDir + f"//Predictions_{crop}_Week{week}.csv", index = False)
        obs = df_preds.loc[(df_preds['Week'] == week), 'TotalYield'].values
        bnn_mean = df_preds.loc[(df_preds['Week'] == week), f'PredMean_Week{week}'].values
        bnn_stdev = df_preds.loc[(df_preds['Week'] == week), f'PredStd_Week{week}'].values

        obs = obs.reshape(-1, 1)
        mse = mean_squared_error(obs, bnn_mean)
        mae = mean_absolute_error(obs, bnn_mean)
        r2 = r2_score(obs, bnn_mean)
        r = r_regression(obs, bnn_mean)
        ic68 = yf.interval_coverage(obs, bnn_mean, bnn_stdev, level = 0.68)
        ic95 = yf.interval_coverage(obs, bnn_mean, bnn_stdev, level = 0.95)
        ic99 = yf.interval_coverage(obs, bnn_mean, bnn_stdev, level = 0.99)
        print("MSE: ", mse)
        print("MAE: ", mae)
        print("R2: ", r2)
        print("Pearson cor: ", r)
        print ("Interval Coverage for 68%: ", ic68)
        print ("Interval Coverage for 95%: ", ic95)
        print ("Interval Coverage for 99%: ", ic99)

        df_acc.loc[df_acc['Week'] == week, df_acc.columns != "Week"] = np.array([mse, mae, r2, r, ic68, ic95, ic99])
        df_acc.to_csv(accDir + f"//AccuracyMetrics_{crop}_Week{week}.csv", index = False)

        ind = sample(list(range(0, len(y_test))), 25)
        x = X_test.TWP_ID.iloc[ind]
        plt.plot(x, obs[ind], "ko")
        plt.errorbar(x, bnn_mean[ind], yerr=bnn_stdev[ind], fmt = 'or')
        plt.xticks(range(len(x)), x, rotation='vertical')
        plt.xlabel("Township ID")
        plt.ylabel(f"{crop}Yield")
        plt.savefig(plotDir + f'\\{crop}Yield_Week{week}_Scatterplot.png', bbox_inches='tight', dpi=1200)
        plt.show()

        # Rerun model on entire dataset (X and y) and save it to a file.
        df_week = df_week.drop(columns = ['MeanTotalYield', 'StdTotalYield'])
        df_week['MeanTotalYield'] = df_week.groupby('TWP_ID')['TotalYield'].transform('mean')
        df_week['StdTotalYield'] = df_week.groupby('TWP_ID')['TotalYield'].transform('std')
        X = df_week.loc[:, df_week.columns != response]
        y = df_week.loc[:, df_week.columns == response].squeeze()
        X_noID = X.drop(columns = ['TWP_ID', 'Year'])
        keras.backend.clear_session()
        dataset_size = len(X_noID)
        kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(dataset_size, dtype=tf.float32))
        model_tfp = tf.keras.Sequential([
            keras.layers.BatchNormalization(),
            tfp.layers.DenseFlipout(96, kernel_divergence_fn=kl_divergence_function),
            keras.layers.ReLU(),
            tfp.layers.DenseFlipout(448, kernel_divergence_fn=kl_divergence_function),
            keras.layers.ReLU(),
            tfp.layers.DenseFlipout(160, kernel_divergence_fn=kl_divergence_function),
            keras.layers.ReLU(),
            keras.layers.Dense(2)
        ])
        model_tfp.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=loss_fun)
        # Add ES
        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        model_tfp.fit(X_noID.values,
                      y.values,
                      epochs=500,
                      batch_size=32,
                      verbose=0,
                      use_multiprocessing=True,
                      callbacks=[early_stopping],
                      validation_split=0.25,
                      )
        model_tfp.save(modelDir + f"//WheatModel_Week{str_week}")

    
