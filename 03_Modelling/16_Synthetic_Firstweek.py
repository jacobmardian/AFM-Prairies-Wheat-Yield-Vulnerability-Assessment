import os
import sys
sys.path.append(r"D:\PhD\YieldProject\Scripts\03_Modelling")
import warnings
from copy import deepcopy
import yieldfunctions as yf
import pandas as pd
import numpy as np
from random import sample
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.feature_selection import r_regression
import tensorflow as tf
from tensorflow import keras
import tensorflow_probability as tfp
from tensorflow.keras.callbacks import EarlyStopping

############################ Create Synthetic Data ######################################
tfd = tfp.distributions
warnings.filterwarnings("ignore")

# Set paths to GDAL in virtual env to avoid proj.db errors
os.environ['PROJ_LIB'] = r"C:\Users\jacob\miniconda3\envs\yieldprojconda\Library\share\proj"
os.environ['GDAL_DATA'] = r"C:\Users\jacob\miniconda3\envs\yieldprojconda\Library\share"
pd.set_option('display.max_columns', None)
import importlib
importlib.reload(yf)

dataDir = "D:\PhD\YieldProject\Data\Final"
modelDir = r"D:\PhD\YieldProject\Output_Detrended_Ha\Models"
trainDir = r"D:\PhD\YieldProject\Output_Detrended_Ha\Training"
synthDir = r"D:\PhD\YieldProject\Output_Detrended_Ha\Synthetic"
predDir = r"D:\PhD\YieldProject\Output_Detrended_Ha\Predictions"

# First, get valid TWP_IDs after filtering
df_pred = pd.read_csv(predDir + "//AllPredictions.csv")
twps = np.unique(df_pred.TWP_ID)

crop = "wheat"
df = pd.read_csv(dataDir + f"//{crop}_AllYears.csv")
df = df[df['TWP_ID'].isin(twps)]
for colname in df.columns[11:16]:
    df[[colname]] = df[[colname]] * 2.47105
#w = np.unique(df['Week'])
#w = list(range(15, 39)) # CHANGE TO 15
#w = [31]
# This data frame is the synthetic data for one week
df_agg = df.groupby('TWP_ID').agg(
    Long=('Long', 'first'),
    Lat=('Lat', 'first'),
    MeanTotalYield=('TotalYield', 'mean'),
    StdTotalYield=('TotalYield', 'std')
).reset_index()
# Get rows for use later
n_twp = len(df_agg)
cats = [0,1,2,3,4,5]
ndvi_levels = ["-1SD", "Mean", "+1SD"]
changeweeks = [18, 22, 27, 31]

# Predictors (ModeCDM, WMeanNDVI) for previous weeks need to be added before running the model for each week
for week in changeweeks:
    str_week = str(week)
    # Get training data
    training = pd.read_csv(trainDir + f"//Training_{crop}_Week{str_week}.csv")
    training = training[training['TWP_ID'].isin(twps)]
    training = training.sort_values(by='TWP_ID').reset_index(drop=True)
    for colname in ['MeanTotalYield', 'StdTotalYield', 'TotalYield']:
        training[[colname]] = training[[colname]] * 2.47105
    print (training)
    # Multiply this df by 6 so we can test for each CDM cat (ND, D0..,D4), then by 3 for each ndvi level (-1SD, etc)
    df_synth = pd.concat([df_agg] * len(cats) * len(ndvi_levels), ignore_index=True)
    if week in changeweeks:
        # Repeat 5 times (for each transition: ND to D0, D0 to D1..) and for each level
        df_agg_rep = pd.concat([df_agg] * (len(cats)-1) * len(ndvi_levels), ignore_index=True)
        # Combine new rows for transitions with other rows for consistent CDMs
        df_synth = pd.concat([df_synth, df_agg_rep], ignore_index=True)
    df_week = deepcopy(df_synth)
    predweeks = list(range(15, week+1)) if week < 19 else list(range(week-4, week+1)) # All weeks included
    for predweek in predweeks:
        predweek_str = str(predweek)
        if week not in changeweeks:
            df_week['Ndvi_Levels'] = [x for x in ndvi_levels for _ in range(n_twp*6)]
            df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)]*3
        elif week in changeweeks:
            df_week['Ndvi_Levels'] = [x for x in ndvi_levels for _ in range(n_twp*6)] + [x for x in ndvi_levels for _ in range(n_twp*5)]
            if predweek != max(predweeks):
                df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)]*3 + [x for x in cats[:-1] for _ in range(n_twp)]*3
            else:
                df_week[f'ModeCDM_{predweek_str}'] = [x for x in cats for _ in range(n_twp)]*3 + [x+1 for x in cats[:-1] for _ in range(n_twp)]*3
        ################################# MonthlyBYCDM #############################################
        if predweek in list(range(15,18)):
            month = 'April'
            monthweeks = list(range(15,18))
        elif predweek in list(range(18,22)):
            month = 'May'
            monthweeks = list(range(18,22))
        elif predweek in list(range(22,27)):
            month = 'June'
            monthweeks = list(range(22,27))
        elif predweek in list(range(27,31)):
            month = 'July'
            monthweeks = list(range(27,31))
        elif predweek in list(range(31,36)):
            month = 'August'
            monthweeks = list(range(31,36))
        elif predweek in list(range(36,39)):
            month = 'September'
            monthweeks = list(range(36,39))
        for cdm in cats:
            mndvi_cdm = df[(df['ModeCDM'] == cdm) & (df['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].mean()
            sndvi_cdm = df[(df['ModeCDM'] == cdm) & (df['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].std()
            plusndvi_cdm = mndvi_cdm + sndvi_cdm
            minusndvi_cdm = mndvi_cdm - sndvi_cdm
            if (cdm == 5):
                # Correct for strange ndvi figures due to low sample size of D4 by taking D3-(D2-D3) NDVI numbers as a linear interp
                mndvi_cdm_prev = df[(df['ModeCDM'] == cdm-1) & (df['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].mean()
                if mndvi_cdm > mndvi_cdm_prev:
                    mndvi_cdm_prev2 = df[(df['ModeCDM'] == cdm - 2) & (df['Week'].isin(monthweeks))].loc[:,"WMeanNdvi"].mean()
                    mndvi_cdm = mndvi_cdm_prev - (mndvi_cdm_prev2 - mndvi_cdm_prev)
            df_week.loc[(df_week['Ndvi_Levels'] == "Mean") & (df_week[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
                mndvi_cdm
            )
            df_week.loc[(df_week['Ndvi_Levels'] == "+1SD") & (df_week[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
                plusndvi_cdm
            )
            df_week.loc[(df_week['Ndvi_Levels'] == "-1SD") & (df_week[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
                minusndvi_cdm
            )
        ################################################ BY CDM ###########################################
        # for cdm in cats:
        #     mndvi_cdm = df[df['ModeCDM'] == cdm].loc[:, "WMeanNdvi"].mean()
        #     sndvi_cdm = df[df['ModeCDM'] == cdm].loc[:, "WMeanNdvi"].std()
        #     plusndvi_cdm = mndvi_cdm + sndvi_cdm
        #     minusndvi_cdm = mndvi_cdm - sndvi_cdm
        #     df_week.loc[(df_week['Ndvi_Levels'] == "Mean") & (
        #             df_week[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
        #         mndvi_cdm
        #     )
        #     df_week.loc[(df_week['Ndvi_Levels'] == "+1SD") & (
        #                 df_week[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
        #         plusndvi_cdm
        #     )
        #     df_week.loc[(df_week['Ndvi_Levels'] == "-1SD") & (
        #                 df_week[f'ModeCDM_{predweek_str}'] == cdm), f'WMeanNdvi_{predweek_str}'] = (
        #         minusndvi_cdm
        #     )
        ################ Initialize values, then calculate values for mean and +/-1 SD - WEEKLYBYTWP #################
        # df_twp = pd.DataFrame(data={'TWP_ID': [x for x in df_week.TWP_ID.unique()]*3,
        #                               'Ndvi_Levels': [x for x in ['Mean', '-1SD', '+1SD'] for _ in range(len(df_week.TWP_ID.unique()))]})
        # df_twp = df_twp.sort_values(by='TWP_ID').reset_index(drop=True)
        # # NDVI Level Mean by TWP, join to df_week - WeeklybyTWP
        # df_twp.loc[df_twp['Ndvi_Levels'] == "Mean", f'WMeanNdvi_{predweek_str}'] = training.groupby('TWP_ID').apply(lambda x: x[f'WMeanNdvi_{predweek_str}'].mean()).values
        # df_twp.loc[df_twp['Ndvi_Levels'] == "-1SD", f'WMeanNdvi_{predweek_str}'] = training.groupby('TWP_ID').apply(lambda x: x[f'WMeanNdvi_{predweek_str}'].mean() - x[f'WMeanNdvi_{predweek_str}'].std()).values
        # df_twp.loc[df_twp['Ndvi_Levels'] == "+1SD", f'WMeanNdvi_{predweek_str}'] = training.groupby('TWP_ID').apply(lambda x: x[f'WMeanNdvi_{predweek_str}'].mean() + x[f'WMeanNdvi_{predweek_str}'].std()).values
        # df_week = df_week.merge(df_twp, on=['TWP_ID', 'Ndvi_Levels'], how='left')
        ############################### WEEKLY SD ALL TWP ############################################
        # df_week.loc[df_week['Ndvi_Levels'] == "Mean", f'WMeanNdvi_{predweek_str}'] = np.mean(
        #     training[f'WMeanNdvi_{predweek_str}'])
        # df_week.loc[df_week['Ndvi_Levels'] == "-1SD", f'WMeanNdvi_{predweek_str}'] = np.mean(
        #     training[f'WMeanNdvi_{predweek_str}']) - np.std(training[f'WMeanNdvi_{predweek_str}'])
        # df_week.loc[df_week['Ndvi_Levels'] == "+1SD", f'WMeanNdvi_{predweek_str}'] = np.mean(
        #     training[f'WMeanNdvi_{predweek_str}']) + np.std(training[f'WMeanNdvi_{predweek_str}'])
        # Get mean and std ndvi for all value the entire time
        # df_week.loc[df_week['Ndvi_Levels'] == "Mean", f'WMeanNdvi_{predweek_str}'] = 0
        # df_week.loc[df_week['Ndvi_Levels'] == "-1SD", f'WMeanNdvi_{predweek_str}'] = -0.08
        # df_week.loc[df_week['Ndvi_Levels'] == "+1SD", f'WMeanNdvi_{predweek_str}'] = 0.08

    # Create model on full dataset
    training = training.drop(columns=['MeanTotalYield', 'StdTotalYield'])
    training['MeanTotalYield'] = training.groupby('TWP_ID')['TotalYield'].transform('mean')
    training['StdTotalYield'] = training.groupby('TWP_ID')['TotalYield'].transform('std')
    X = training.loc[:, training.columns != "TotalYield"]
    y = training.loc[:, training.columns == "TotalYield"].squeeze()
    X_noID = X.drop(columns=['TWP_ID', 'Year'])
    keras.backend.clear_session()
    dataset_size = len(X_noID)
    kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(dataset_size, dtype=tf.float32))
    model_tfp = tf.keras.Sequential([
        keras.layers.BatchNormalization(),
        tfp.layers.DenseFlipout(96, kernel_divergence_fn=kl_divergence_function),
        keras.layers.ReLU(),
        tfp.layers.DenseFlipout(448, kernel_divergence_fn=kl_divergence_function),
        keras.layers.ReLU(),
        tfp.layers.DenseFlipout(160, kernel_divergence_fn=kl_divergence_function),
        keras.layers.ReLU(),
        keras.layers.Dense(2)
    ])
    loss_fun = yf.testloss_3 if week in list(range(16, 19)) + list(range(28, 36)) else yf.testloss
    model_tfp.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=loss_fun)
    # Add ES
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model_tfp.fit(X_noID.values,
                  y.values,
                  epochs=500,
                  batch_size=32,
                  verbose=0,
                  use_multiprocessing=True,
                  callbacks=[early_stopping],
                  validation_split=0.25,
                  )
    # Predict
    # First, prep synthetic data
    df_test = df_week.drop(columns=['TWP_ID', 'Ndvi_Levels'])
    df_test = df_test.reindex(columns=X_noID.columns)
    num_monte_carlo_samples = 100
    mean_preds = np.mean(np.array(
        np.stack([model_tfp.predict(df_test.values)[:, 0] for _ in range(num_monte_carlo_samples)])).squeeze(),
                         axis=0)
    mean_stdev = np.mean(np.array(np.stack(
        [np.exp(model_tfp.predict(df_test.values)[:, 1]) for _ in range(num_monte_carlo_samples)])).squeeze(),
                         axis=0)
    stdev_means = np.std(np.array(
        np.stack([model_tfp.predict(df_test.values)[:, 0] for _ in range(num_monte_carlo_samples)])).squeeze(),
                         axis=0)
    # Add together for total uncert
    stdev_preds = mean_stdev + stdev_means

    # Add to df
    df_week["MeanYieldPred"] = mean_preds
    df_week["StdYieldPred"] = stdev_preds
    df_week["Week"] = week
    df_week.to_csv(synthDir + f"//SyntheticPreds_{crop}_Week{str_week}.csv", index = False)
