# -*- coding: utf-8 -*-
"""
Created on Wed Jan  4 14:19:45 2023

@author: jacob

# Analyze how crop yields change each month based on current CCAP conditions
# (i.e., use only average or better crops as some crops will have lwoer yields due to late seeding/other reasons)
# How does that month's CDM rating change crop yield?
"""
# os libraries
import os, glob, sys, copy, gc
# dask
import dask
#from dask import delayed
#from dask.distributed import Client
# Geospatial
#import numpy as np
#import geopandas as gpd
# import rasterio
import xarray as xr
import rioxarray as rxr
# Others
from datetime import datetime
# My functions
sys.path.append(r"D:\PhD\YieldProject\Scripts\02_Preprocess")
import yieldfunctions as yf

# Set paths to GDAL in virtual env to avoid proj.db errors
os.environ['PROJ_LIB'] = r"C:\Users\jacob\.conda\envs\yieldproj\Library\share\proj"
os.environ['GDAL_DATA'] = r"C:\Users\jacob\.conda\envs\yieldproj\Library\share"

# Config dask
dask.config.set(**{'array.slicing.split_large_chunks': True})

# User params
rawDir = r"D:\PhD\YieldProject\Data\NDVI_Raw" # Location of NDVI data
baselineDir = r"D:\PhD\YieldProject\Data\NDVI_Baselines" # Loc of NDVI baselines
clipshp = r"D:\PhD\AAFC_Data\Boundary\AgExtent_Prairies.shp" # Loc of shp for clipping
anomDir = r"D:\PhD\YieldProject\Data\NDVI_Anomalies" # Loc of output dir for NDVI anoms
proj = rxr.open_rasterio(r"D:\PhD\YieldProject\Data\CCAP\ccap_test.tif").spatial_ref.crs_wkt

# Create DataArrays for each variable
raw = yf.stack(rawDir, clipshp)
res = float(raw.spatial_ref.GeoTransform.split(" ")[1])
baseline = yf.stack(baselineDir, clipshp, end = 2010)
baseline = yf.align_rasters(baseline, raw)

# # Calculate anomalies (raw - baseline), reproject and align
anom = yf.calc_anomalies(raw, baseline, proj, res, anomDir)
ncfPath = anomDir + "\\NDVIAnomalies_20102021_Baseline20022021.nc"
anom.rename({'band_data': "ndvi"}).to_netcdf(path = ncfPath, engine="netcdf4", encoding = {"ndvi": {"dtype": "f4", 'zlib': True}})
# Open from netcdf instead of individual files
anom = xr.open_dataset(ncfPath)
anom = anom.chunk({'time': 1, 'x': 500, 'y': 500})





