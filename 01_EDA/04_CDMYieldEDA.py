# -*- coding: utf-8 -*-
"""
Created on Sun Dec 18 16:35:58 2022

@author: jacob
"""

import os
import glob
import pandas as pd
import geopandas as gpd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

yieldPath = r"D:\PhD\YieldProject\Data\Yield"
for yieldFile in glob.glob(yieldPath + "\*_Ordinal*.csv"):
    crop = os.path.basename(yieldFile).split("CDM")[1].split("_")[0]
    print(crop)
    yieldTable = pd.read_csv(yieldFile)
    
    #################### Make correlation bar plot ######################
    # Get Correlations the long way so you can have p-values
    # df = pd.DataFrame()
    # feat1s = []
    # feat2s = []
    # corrs = []
    # p_values = []
    
    # for feat1 in yieldTable.columns[2:]:
    #     for feat2 in yieldTable.columns[2:]:
    #         if feat1 != feat2:
    #             feat1s.append(feat1)
    #             feat2s.append(feat2)
    #             corr, p_value = scipy.stats.kendalltau(yieldTable[feat1], 
    #                                                    yieldTable[feat2])
    #             corrs.append(corr)
    #             p_values.append(p_value)

    # df['Feature_1'] = feat1s
    # df['Feature_2'] = feat2s
    # df['Correlation'] = corrs
    # df['p_value'] = p_values
    # df = df[(df['Feature_1'] == "Yield")]
    # df = df.sort_values(by = "Correlation")
    # df.reset_index(inplace=True, drop=True)
    
    # # Bar plots with statsitical significance
    # # Frist define function to plot signifiance
    # def convert_pvalue_to_asterisks(pvalue):
    #     if pvalue <= 0.05:
    #         return "*"
    #     else:
    #         return ""
    # sig = []
    # for i in range(len(df)):
    #     sig.append(convert_pvalue_to_asterisks(df['p_value'][i]))
    # df['sig'] = sig
    # # Plot barplots 
    # sns.set_theme(style="whitegrid")
    # plt.figure(figsize=(9, 7), dpi=300)
    # plots = sns.barplot(y="Feature_2", x="Correlation", data=df, color="b")
    # i = 0
    # for bar in plots.patches:
    #     # Using Matplotlib's annotate function and
    #     # passing the coordinates where the annotation shall be done
    #     # x-coordinate: bar.get_x() + bar.get_width() / 2
    #     # y-coordinate: bar.get_height()
    #     # free space to be left to make graph pleasing: (0, 0)
    #     # ha and va stand for the horizontal and vertical alignment
    #     print(bar)
    #     if bar.get_width() < 0:
    #         xy = (-5,-5)
    #     else:
    #         xy = (5, -5)
    #     plots.annotate(df['sig'][i],
    #                      (bar.get_width(), 
    #                       bar.get_y() + bar.get_height() / 2), 
    #                      ha='center', va='center',
    #                      size=15, xytext=xy,
    #                      textcoords='offset points')
    #     i = i+1
    # plt.ylabel("Variable")
    # plt.xlabel("Kendall Correlation")
    # plt.title("Correlation Between CDM Predictors and {} Yield".format(crop))
    # plt.show()
    
    # Plot correlation matrix
    # cor_mat = yieldTable.iloc[:,2:].corr(method = "kendall")
    # # sn.heatmap(cor_mat)
    # # plt.show()
    # cor = cor_mat.loc[:,'Yield']
    # cor = cor.iloc[1:]
    # cor = cor.sort_values()
    
    # Plot barplots 
    # plt.figure(figsize=(9, 7), dpi=300)
    # plt.barh(cor.index, cor)
    # plt.ylabel("Variable")
    # plt.xlabel("Kendall Correlation")
    # plt.title("Correlation Between CDM Predictors and {} Yield".format(crop))
    # plt.show()
    
    #################### Make table for CDM months ######################
    # Prepare df
    
    # Plot mean and sd of yield for different CDM vals
    meandf = pd.DataFrame()
    severity = ["ND", "D0", "D1", "D2", "D3", "D4"]
    meandf['Severity'] = severity
    mons = yieldTable.columns[3:15].to_list()
    for mon in mons:
        monVals = []
        i=0
        for sev in severity:
            # Add & (yieldTable['Yield'] != 0) to remove years with no yield
            yld = np.array(yieldTable[(yieldTable[mon] == i)].loc[:,"Yield"])
            meanYld = yld.mean()
            if not np.isnan(meanYld):
                meanYld = int(meanYld)
            sdYld = yld.std()
            sqrt_n = np.sqrt(len(yld))
            se = 2*(sdYld / sqrt_n)
            if not np.isnan(se):
                se = int(se)
            out = str(meanYld) + ' +/- ' + str(se)
            monVals.append(out)
            i+=1
        meandf[mon] = monVals
    print (meandf) # uncertainty reported at 95% confidence level
    # meandf.to_csv(r"D:\PhD\YieldProject\Plots\MeanTableWithZeroes_{}.csv".format(crop),
    #               index=False)
    
    ###########  Create shpfile of yield variability (CV) ################
    # cvdf = pd.DataFrame()
    # cvdf['TWP_ID'] = np.unique(yieldTable['TWP_ID'])
    # cvlist = []
    # for twp in np.unique(yieldTable['TWP_ID']):
    #     twpdf = yieldTable[yieldTable['TWP_ID'] == twp]
    #     vals = twpdf.iloc[:,2]
    #     mean = vals[vals != 0].mean()
    #     sd = vals[vals != 0].std()
    #     cv = round((mean / sd) * 100, 2)
    #     cvlist.append(cv)
    # cvdf['CV'] = cvlist
    
    # # Load the right shapefile, join CV data to it
    # shpname = os.path.join(yieldPath, "{}Yield_Township.shp".format(crop))
    # twpshp = gpd.read_file(shpname)
    # twpshp['TWP_ID'] = twpshp['TWP_ID'].astype('string')
    # twpshp = twpshp.merge(cvdf, on='TWP_ID')
    # outname = os.path.join(yieldPath, "YieldCV_{}.shp".format(crop))
    # twpshp.to_file(outname)


    
    

    
    
    
